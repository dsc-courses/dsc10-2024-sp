{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Hypothesis Testing and Permutation Testing\n",
    "\n",
    "## Due Tuesday, May 28th at 11:59PM\n",
    "\n",
    "Welcome to Homework 6, the last homework of the quarter! This homework covers hypothesis testing ([CIT 11](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)) and permutation testing ([CIT 12](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Ed. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "def show_clt_slides():\n",
    "    src = 'https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000&rm=minimal'\n",
    "    width = 700\n",
    "    height = 370\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Was it by Random Chansey? üé≤\n",
    "\n",
    "<img src='images/chansey.png' width='250'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You recently decided to buy the video game *Pok√©mon Yellow* from someone on Ebay. The seller tells you that they've modified the game so that the probabilities of encountering certain Pok√©mon in certain locations have been altered. However, the seller doesn't tell you which specific locations have had their probability models changed and what they've been changed to.\n",
    "\n",
    "As you are playing *Pok√©mon Yellow*, you arrive at the Safari Zone, one of the most iconic locations in the game. You're curious as to your chances of encountering your favorite Pok√©mon, Chansey, in this location. You go onto [Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Kanto_Safari_Zone#Area_1) to find the probability model for this location, and you discover that for each Pok√©mon encounter in the Safari Zone, there is a 4% chance of encountering Chansey. \n",
    "\n",
    "After a few hours of gameplay in the Safari Zone, you have encountered Chansey **48 times out of 821 total Pok√©mon encounters**, which is almost 6% of the time! You start to suspect that the Safari Zone may have been one of the locations in which the previous owner of the game changed the probability model.\n",
    "\n",
    "To test this, you decide to run a hypothesis test with the following hypotheses:\n",
    "\n",
    "**Null Hypothesis**: In your copy of *Pok√©mon Yellow*, the probability of encountering Chansey at each Pok√©mon encounter in the Safari Zone is 4%. \n",
    "\n",
    "**Alternative Hypothesis**: In your copy of *Pok√©mon Yellow*, the probability of encountering Chansey at each Pok√©mon encounter in the Safari Zone is greater than 4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Complete the implementation of the function `one_simulation`, which has no arguments. It should randomly generate 821 Pok√©mon encounters in the Safari Zone and return the **proportion** of encountered Pok√©mon that were Chansey. \n",
    "\n",
    "***Hint:*** Use `np.random.multinomial`. You don't need a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulation():\n",
    "    ...\n",
    "    \n",
    "one_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** The test statistic for our hypothesis test will be the difference between the proportion of Chansey encounters in a given sample of 821 Safari Zone encounters and the expected proportion of Chansey encounters, i.e.\n",
    "\n",
    "$$\\text{test statistic} = \\text{proportion of Chansey encounters in sample} - 0.04$$\n",
    "\n",
    "\n",
    "Let's conduct 10,000 simulations. Create an array named `proportion_diffs` containing 10,000 simulated values of the test statistic described above. Utilize the function created in the previous question to perform this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_diffs = ...\n",
    "\n",
    "# Visualize with a histogram. Don't change anything below.\n",
    "bpd.DataFrame().assign(proportion_differences=proportion_diffs).plot(kind='hist', bins=20, density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=(48 / 821 - 0.04), color='black', linewidth=4, label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Calculate the p-value for this hypothesis test, and assign the result to `safari_zone_p`.\n",
    "\n",
    "***Hint:*** Do large values of our test statistic favor the alternative hypothesis, or do small values of our test statistic favor the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safari_zone_p = ...\n",
    "safari_zone_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `safari_zone_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safari_zone_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** In this question, we chose as our test statistic the proportion of Chansey encounters in the Safari Zone minus 0.04. But this is not the only statistic we could have chosen; there are many that could have worked here. \n",
    "\n",
    "From the options below, choose the test statistic that would **not** have worked for this hypothesis test, and assign 1, 2, 3, or 4 to the variable `bad_choice`.\n",
    "\n",
    "1. The number of Chansey encounters out of 821 enounters in the Safari Zone.\n",
    "1. The proportion of Chansey encounters in the Safari Zone.\n",
    "1. 0.04 minus the proportion of Chansey encounters in the Safari Zone.\n",
    "1. The absolute difference between 0.04 and the proportion of Chansey encounters in the Safari Zone.\n",
    "\n",
    "***Hint:*** Our goal is to find a test statistic that will help us determine whether we encounter Chansey **more** often than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_choice = ...\n",
    "bad_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <span>Tetris Blocks</span> üì± "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/tetris.png' width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tetris is a classic video game where the player moves differently shaped puzzle pieces in an attempt to fit them neatly together in order to clear rows and prevent the board from filling up. The longer you can stop your board from filling up, the higher your score. There are seven unique shapes, each composed of four squares arranged in different shapes. The official name for this type of block is a [tetromino](https://en.wikipedia.org/wiki/Tetromino)!\n",
    "\n",
    "<img src='images/tetris-blocks.webp' width='600'>\n",
    "\n",
    "The seven types of blocks used in Tetris include: `'I-block'`, `'J-block'`, `'L-block'`, `'O-block'`, `'S-block'`, `'T-block'`, and `'Z-block'`. The most coveted block is the `'I-block'`, which can clear several rows at once *if* it appears at the appropriate time. Unfortunately, there is no publicly available information on the exact probabilities of getting any of the seven block types during a game of Tetris. However, our DSC 10 tutor Daniel plays Tetris a lot, and based on his experience with the game, he proposes the following probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type | Daniel's Estimated Probability|\n",
    "| --- | --- |\n",
    "| I-block | $0.14$ |\n",
    "| J-block | $0.15$ |\n",
    "| L-block | $0.12$ |\n",
    "| O-block | $0.18$ |\n",
    "| S-block | $0.15$ |\n",
    "| T-block | $0.14$ |\n",
    "| Z-block | $0.12$ |\n",
    "\n",
    "We'll store this distribution in an array, in the order shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "daniel_dist = np.array([0.14, 0.15, 0.12, 0.18, 0.15, 0.14, 0.12])\n",
    "daniel_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the validity of Daniel's model, you collect data from many Tetris players. You learn that in total, out of 2,902 Tetris pieces placed:\n",
    "- 415 were `'I-block'`,\n",
    "- 462 were `'J-block'`,\n",
    "- 367 were `'L-block'`,\n",
    "- 539 were `'O-block'`,\n",
    "- 413 were `'S-block'`,\n",
    "- 358 were `'T-block'`,\n",
    "- the rest were `'Z-block'`.\n",
    "\n",
    "You then calculate the **empirical** type distribution using the data you collected and store it in an array as well (in the same order as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "empirical_dist = np.array([415, 462, 367, 539, 413, 358, 2902 - (415 + 462 + 367 + 539 +413 + 358)]) / 2902\n",
    "empirical_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `empirical_dist` is not identical to `daniel_dist`, it's still possible that Daniel's model is plausible, and that the observed differences are due to random chance. Let's run a hypothesis test to investigate further, using the following hypotheses: \n",
    "\n",
    "**Null Hypothesis**: The types of Tetris blocks are drawn randomly from the distribution `daniel_dist`.\n",
    "\n",
    "**Alternative Hypothesis**: The types of Tetris blcoks are _not_ drawn randomly from the distribution `daniel_dist`.\n",
    "\n",
    "Note that this hypothesis test involves seven proportions, one for each block shape.\n",
    "\n",
    "**Question 2.1.**  Which of the following is **not** a reasonable choice of test statistic for this hypothesis test? Assign 1, 2, or 3 to the variable `unreasonable_test_statistic`. \n",
    "1. The sum of the absolute difference between the proposed distribution (Daniel's expected proportion of types) and the empirical distribution (actual proportion of types).\n",
    "1. The absolute difference between the sum of the proposed distribution (Daniel's expected proportion of types) and the sum of the empirical distribution (actual proportion of types).\n",
    "1. Among all seven Tetris block types, the largest absolute difference between Daniel's expected proportion and the actual proportion of blocks of that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreasonable_test_statistic = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** We'll use the TVD, i.e. **total variation distance**, as our test statistic. Below, complete the implementation of the function `total_variation_distance`, which takes in two distributions (stored as arrays) as arguments and returns the total variation distance between the two arrays.\n",
    "\n",
    "Then, use the function `total_variation_distance` to determine the TVD between the type distribution proposed by Daniel and the empirical type distribution you observed. Assign this TVD to `observed_tvd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(first_distrib, second_distrib):\n",
    "    '''Computes the total variation distance between two distributions.'''\n",
    "    ...\n",
    "\n",
    "observed_tvd = ...\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Now, we'll calculate 5,000 simulated TVDs to see what a typical TVD between the proposed distribution and an empirical distribution would look like if Daniel's model were accurate. Since our real-life data includes 2,902 Tetris blocks, in each trial of the simulation, we'll:\n",
    "- draw 2,902 Tetris blocks at random from Daniel's proposed distribution, then \n",
    "- calculate the TVD between **Daniel's proposed type distribution** and the **empirical type distribution from the simulated sample**. \n",
    "\n",
    "Store these 5,000 simulated TVDs in an array called `simulated_tvds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simulated_tvds = ...\n",
    "\n",
    "# Visualize the distribution of TVDs with a histogram\n",
    "bpd.DataFrame().assign(simulated_tvds=simulated_tvds).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=observed_tvd, color='black', linewidth=4, label='observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Now, determine the p-value for our test by finding the proportion of times in our simulation that we saw a TVD greater than or equal to our observed TVD. Assign your result to `tetris_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tetris_p = ...\n",
    "tetris_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `tetris_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. There is not enough evidence to say if the observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetris_conclusion = ...\n",
    "tetris_conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Award-Winning Anime üê±‚Äçüë§üèÜ\n",
    "<img src='images/attack-on-titan.jpg' width='1000'>\n",
    "\n",
    "The `animes.csv` dataset from [Kaggle](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset?resource=download) contains more than 10,000 anime TV series, movies, and OVAs (original video animations). See if your favorite anime is in there!\n",
    "\n",
    "The data contains six columns: `'Name'`, `'English name'`, `'Episodes'`, `'Aired'`, `'Genres'`, `'Score'`. Let's read it in and store it as a DataFrame named `anime`.\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| `'Name'` | The name of the anime in its original language |\n",
    "| `'English name'` | The English name of the anime |\n",
    "| `'Episodes'` | The number of episodes in the anime |\n",
    "| `'Aired'` | The dates when the anime was aired |\n",
    "| `'Genres'` | The genres of the anime, separated by commas |\n",
    "| `'Score'` | The score given to the anime |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = bpd.read_csv('data/animes.csv')\n",
    "anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some rows of the DataFrame preview above, such as the first row for `'Cowboy Bebop'`, include `'Award-Winning'` in the `'Genres'` column. This means the anime won an award, such as the Crunchyroll Anime Award. In 2024, this award was given to  *Jujutsu Kaisen* in case you want to check it out.\n",
    "\n",
    "In this section, we will explore whether the scores for award-winning animes come from the same distribution as non-winning animes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Complete the implementation of the function `label_award`, which takes in a string of genres associated with a single row of `anime` and returns either `'Award-Winning'` or `'No Award'`. \n",
    "\n",
    "Once you've done that, use your function to help you create a new DataFrame named `anime_labeled` that has all the same columns as `anime`, in the same order, with an additional column named `'Award_Status'` that contains whether the anime is award-winning. The `'Award_Status'` column should contain only two distinct values: `'Award-Winning'` and `'No Award'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_award(genres): \n",
    "    ...\n",
    "    \n",
    "anime_labeled = ...\n",
    "anime_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Using the DataFrame `anime_labeled`, calculate the difference between the **mean** `'Score'` of award-winning animes and non-winning animes. Assign your answer to `observed_difference`.\n",
    "\n",
    "$$\\text{observed difference} = \\text{mean award-winning anime score} - \\text{mean non-winning anime score}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** What does the number you obtained for `observed_difference` mean? Assign `interpretation` to 1, 2, 3, or 4, corresponding to the best explanation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our sample, the mean award-winning anime score is higher than the mean non-winning anime score by about 82 percent.\n",
    "1. In our sample, the mean award-winning anime score is higher than the mean non-winning anime score by about 0.82 percent.\n",
    "1. In our sample, the mean award-winning anime score is higher than the mean non-winning anime score by about 0.82 points.\n",
    "1. In our sample, the mean non-winning anime score is higher than the mean award-winning anime score by about 82 percent.\n",
    "1. In our sample, the mean non-winning anime score is higher than the mean award-winning anime score by about 0.82 percent.\n",
    "1. In our sample, the mean non-winning anime score is higher than the mean award-winning anime score by about 0.82 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we want to conduct a **permutation test** to see if it is by chance that the average score for award-winning animes is higher than the average score of non-winning animes in our sample, or if award-winning animes actually have a higher score on average than non-winning animes.\n",
    "\n",
    "- **Null Hypothesis**: The scores of award-winning animes and non-winning animes come from the same distribution.  \n",
    "- **Alternative Hypothesis**: The scores of award-winning animes are higher on average than the scores of non-winning animes.\n",
    "\n",
    "**Question 3.4.** Assign `reduced_df` to a DataFrame with only two columns, `'Award_Status'` and `'Score'`, since these are the only relevant columns in `anime_labeled` for this permutation test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = ...\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Run a permutation test to see if the `observed_difference` is a statistically significant difference. To run this permutation test, simulate 1000 values of the test statistic. For each test statistic, shuffle the `'Award_Status'` column of `reduced_df` and calculate the difference in mean score (award-winning minus non-winning). Store your 1000 differences in the `differences` array. Be sure not to shuffle the `'Score'` column. \n",
    "\n",
    "***Hint:*** It's a good idea to simulate one value of the test statistic before putting everything in a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "differences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.** Compute a p-value for this hypothesis test and assign your answer to `anime_p`. To decide whether to use `<=` or `>=` in the calculation of the p-value, think about whether larger values or smaller values of our test statistic favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_p = ...\n",
    "anime_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Assign the variable `anime_conclusion` to a **list** of all the true statements below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We accept the null hypothesis at the 0.01 significance level.\n",
    "1. We reject the null hypothesis at the 0.01 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.01 significance level.\n",
    "1. We accept the null hypothesis at the 0.05 significance level.\n",
    "1. We reject the null hypothesis at the 0.05 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.05 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Suppose in this question you had shuffled the `'Score'` column instead and kept the `'Award_Status'` column in the same order. Assign `shuffled_score` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "\n",
    "1. The new p-value from shuffling `'Score'` would be $1 - p$, where $p$ is the old p-value from shuffling `'Award_Status'` (i.e. your answer to Question 3.6).\n",
    "1. We would need to change our null hypothesis in order to shuffle the `'Score'` column. \n",
    "1. There would be no difference in the conclusion of the test if we had shuffled the `'Score'` column instead.\n",
    "1. The `'Score'` column cannot be shuffled because it contains numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Which of the following choices best describes the purpose of shuffling one of the columns in our dataset in a permutation test? Assign `why_shuffle` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "1. Shuffling mitigates noise in our data by generating new permutations of the data.\n",
    "1. Shuffling is a special case of bootstrapping and allows us to produce interval estimates.\n",
    "1. Shuffling allows us to generate new data under the null hypothesis, which we can use in testing our hypothesis.\n",
    "1. Shuffling allows us to generate new data under the alternative hypothesis, which helps us identify when the data come from different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "why_shuffle = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New York Times Mini Crossword üß©üïê\n",
    "<img src='images/nyt_mini_crossword.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The New York Times Mini Crossword](https://www.nytimes.com/crosswords/game/mini) is a smaller and quicker version of the traditional crossword puzzle. It features straightforward clues and is designed to be completed in a few minutes. After completeing the puzzle, players have the option to send the time it took to complete the puzzle to their friends, to try to compete for the lowest time.\n",
    "\n",
    "Ciro and Athu have been playing the New York Times Mini Crossword for a couple months, often sending each other the time it takes for them to complete each puzzle. Today, Ciro's time was much faster than Athu's so he bragged that he is better than Athu at the game. Athu vehemently disagrees and thinks that they are equally skilled.\n",
    "\n",
    "Since the two of them have learned about hypothesis testing in DSC10, they decided to look at their history of times to determine if they were equally skilled or if one of them was better than the other.\n",
    "\n",
    "Let's look at all the data that they collected. Each entry in the `'Time'` column represents the amount of time it took in seconds for one person to complete the New York Times Mini Crossword on a single day. There are 40 times for Ciro and 40 times for Athu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_cw = bpd.read_csv('data/mini-crossword.csv')\n",
    "mini_cw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Now let's address the question: how does the average time for Ciro to complete the crossword compare to Athu's average time? Create a DataFrame called `ciro` that contains only the times for Ciro, and set `ciro_mean` to the mean time to complete the crossword for Ciro. Similarly, create a DataFrame `athu` for Athu and compute `athu_mean`. Finally, set `observed_diff_mean`, to the difference in mean times to complete the crossword in our sample, computed as follows.\n",
    "\n",
    "$$\\text{difference} = \\text{mean time to complete the crossword for Ciro} - \\text{mean time to complete the crossword for Athu}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciro = ...\n",
    "athu = ...\n",
    "ciro_mean = ...\n",
    "athu_mean = ...\n",
    "observed_diff_mean = ...\n",
    "observed_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you answered Question 4.1 correctly, you should have noticed a difference in the average times between Ciro and Athu. But we only have a small sample of their performance on the Mini Crossword, so it's possible that this difference is merely a result of the specific samples we happened to collect. Let's do a **hypothesis test** to find out if there's actually a difference in their abilities. We'll state our hypotheses as follows:\n",
    "\n",
    "- **Null Hypothesis**: The average time it takes to complete the New York Times Mini Crossword is the same for both Ciro and Athu. In other words, their difference in average time is equal to 0 seconds.\n",
    "\n",
    "- **Alternative Hypothesis**: The average time it takes to complete the New York Times Mini Crossword is not the same for both Ciro and Athu. In other words, the difference in average time between the two of them is not equal to 0 seconds.\n",
    "\n",
    "\n",
    "Since we are able to frame our hypothesis test as a question of whether a certain population parameter ‚Äì the difference in average times ‚Äì is equal to a specific value, we can **test our hypotheses by constructing a confidence interval** for this parameter. For a refresher on this method, refer to [CIT 13.4](https://inferentialthinking.com/chapters/13/4/Using_Confidence_Intervals.html) or the human body temperature example from [Lecture 22](https://dsc10.com/resources/lectures/lec22/lec22.html).\n",
    "\n",
    "***Note:*** We are **not** conducting a permutation test here, although that would also be a valid approach to test these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Compute 1000 **bootstrapped estimates** for the difference in average times between Ciro and Athu. As in Question 4.1, calculate the difference as Ciro minus Athu. Store your 1000 estimates in the `difference_means` array.\n",
    "\n",
    "You should generate your Ciro resamples by sampling from `ciro`, and your Athu resamples by sampling from `athu`. Do not use the combined dataset `mini_cw` for this task, otherwise you might not wind up with 40 of each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_means = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "difference_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize your estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(BootstrappedDifferenceMeans = difference_means).plot(kind = 'hist', density=True, ec='w', bins=20, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Compute a 95% confidence interval for the difference in mean times (as before, in the order Ciro minus Athu). Assign the left and right endpoints of this confidence interval to `left_endpoint` and `right_endpoint` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = ...\n",
    "right_endpoint = ...\n",
    "\n",
    "print('Bootstrapped 95% confidence interval for the mean difference in time to complete the crossword for Ciro and Athu:\\n [{:f}, {:f}]'.format(left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Based on the confidence interval you've created, would you reject the null hypothesis at the 0.05 significance level? Set `reject_null` to True if you would reject the null hypothesis, and False if you would not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5.** What if Ciro and Athu collected their times in minutes instead of seconds? Would your hypothesis test still come to the same conclusion either way? Set `same_conclusion` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 6 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
